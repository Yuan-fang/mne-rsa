{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor-level RSA example on the kiloword EEG dataset\n",
    "\n",
    "This example demonstrates how to perform representational similarity analysis (RSA) on EEG data, using a searchlight approach.\n",
    "\n",
    "In the searchlight approach, representational similarity is computed between the model and searchlight \"patches\". A patch is defined by a seed point (e.g. sensor Pz) and everything within the given radius (e.g. all sensors within 4 cm. of Pz). Patches are created for all possible seed points (e.g. all sensors), so you can think of it as a \"searchlight\" that moves from seed point to seed point and everything that is in the spotlight is used in the computation.\n",
    "\n",
    "The radius of a searchlight can be defined in space, in time, or both. In this example, our searchlight will have a spatial radius of 4.5 cm. and a temporal radius of 50 ms.\n",
    "\n",
    "The dataset will be the kiloword dataset [1]: approximately 1,000 words were presented to 75 participants in a go/no-go lexical decision task while event-related potentials (ERPs) were recorded.\n",
    "\n",
    "[1] Dufau, S., Grainger, J., Midgley, KJ., Holcomb, PJ. A thousand words are worth a picture: Snapshots of printed-word processing in an event-related potential megastudy. Psychological science, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import mne\n",
    "import mne_rsa\n",
    "\n",
    "# Configure the graphics engine: figures should be embedded in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNE-Python contains a build-in data loader for the kiloword dataset. We use it here to read it as 960 epochs. Each epoch represents the brain response to a single word, averaged across all the participants. For this example, we speed up the computation, at a cost of temporal precision, by downsampling the data from the original 250 Hz. to 100 Hz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\wmvan\\mne_data\\MNE-kiloword-data/kword_metadata-epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     920.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "960 matching events found\n",
      "No baseline correction applied\n",
      "Adding metadata with 8 columns\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "data_path = mne.datasets.kiloword.data_path(verbose=True)\n",
    "epochs = mne.read_epochs(data_path + '/kword_metadata-epo.fif')\n",
    "epochs = epochs.resample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `epochs` object contains a `.metadata` field that contains information about the 960 words that were used in the experiment. Let's have a look at the metadata for the 10 random words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "      <th>Concreteness</th>\n",
       "      <th>WordFrequency</th>\n",
       "      <th>OrthographicDistance</th>\n",
       "      <th>NumberOfLetters</th>\n",
       "      <th>BigramFrequency</th>\n",
       "      <th>ConsonantVowelProportion</th>\n",
       "      <th>VisualComplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>squad</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>2.225309</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>156.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>75.786439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>reversal</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1.991226</td>\n",
       "      <td>2.65</td>\n",
       "      <td>8.0</td>\n",
       "      <td>859.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>60.545879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>poem</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>2.414973</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>82.239855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>horizon</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>2.515874</td>\n",
       "      <td>2.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>521.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>60.077749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>concept</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>2.930440</td>\n",
       "      <td>1.95</td>\n",
       "      <td>7.0</td>\n",
       "      <td>900.285714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>67.052144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>graduate</td>\n",
       "      <td>4.850000</td>\n",
       "      <td>2.093422</td>\n",
       "      <td>2.65</td>\n",
       "      <td>8.0</td>\n",
       "      <td>630.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>70.751988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>hunk</td>\n",
       "      <td>4.388889</td>\n",
       "      <td>1.531479</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>284.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>66.655696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>crew</td>\n",
       "      <td>4.850000</td>\n",
       "      <td>2.583199</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>566.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>71.259695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>camp</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>3.030600</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>656.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>79.461521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>report</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>3.269746</td>\n",
       "      <td>1.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>718.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>60.874401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WORD  Concreteness  WordFrequency  OrthographicDistance  \\\n",
       "798     squad      4.550000       2.225309                  1.70   \n",
       "956  reversal      3.700000       1.991226                  2.65   \n",
       "262      poem      4.450000       2.414973                  1.85   \n",
       "648   horizon      4.950000       2.515874                  2.90   \n",
       "885   concept      2.150000       2.930440                  1.95   \n",
       "704  graduate      4.850000       2.093422                  2.65   \n",
       "520      hunk      4.388889       1.531479                  1.25   \n",
       "274      crew      4.850000       2.583199                  1.65   \n",
       "734      camp      5.350000       3.030600                  1.20   \n",
       "820    report      5.150000       3.269746                  1.75   \n",
       "\n",
       "     NumberOfLetters  BigramFrequency  ConsonantVowelProportion  \\\n",
       "798              5.0       156.200000                  0.600000   \n",
       "956              8.0       859.000000                  0.625000   \n",
       "262              4.0       298.000000                  0.500000   \n",
       "648              7.0       521.428571                  0.571429   \n",
       "885              7.0       900.285714                  0.714286   \n",
       "704              8.0       630.375000                  0.500000   \n",
       "520              4.0       284.250000                  0.750000   \n",
       "274              4.0       566.500000                  0.750000   \n",
       "734              4.0       656.500000                  0.750000   \n",
       "820              6.0       718.666667                  0.666667   \n",
       "\n",
       "     VisualComplexity  \n",
       "798         75.786439  \n",
       "956         60.545879  \n",
       "262         82.239855  \n",
       "648         60.077749  \n",
       "885         67.052144  \n",
       "704         70.751988  \n",
       "520         66.655696  \n",
       "274         71.259695  \n",
       "734         79.461521  \n",
       "820         60.874401  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.metadata.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick something obvious for this example and build a dissimilarity matrix (DSM) based on the number of letters in each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsm_vis = mne_rsa.compute_dsm(epochs.metadata[['NumberOfLetters']], metric='euclidean')\n",
    "mne_rsa.plot_dsms(dsm_vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above DSM will serve as our \"model\" DSM. In this example RSA analysis, we are going to compare the model DSM against DSMs created from the EEG data. The EEG DSMs will be created using a \"searchlight\" pattern. We are using squared Euclidean distance for our DSM metric, since we only have a few data points in each searlight patch. Feel free to play around with other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_result = mne_rsa.rsa_epochs(epochs,      # The EEG data\n",
    "                                dsm_vis,     # The model DSM\n",
    "                                epochs_dsm_metric='sqeuclidean',  # Metric to use to compute the EEG DSMs\n",
    "                                rsa_metric='kendall-tau-a',   # Metric to use to compare the model and EEG DSMs\n",
    "                                spatial_radius=45,  # Spatial radius of the searchlight patch\n",
    "                                temporal_radius=0.05,   # Temporal radius of the searchlight path\n",
    "                                tmin=0.15, tmax=0.25,  # To save time, only analyze this time interval\n",
    "                                n_jobs=1,  # Only use one CPU core. Increase this for more speed.\n",
    "                                verbose=True)  # Print progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is packed inside an MNE-Python [`Evoked`](https://mne.tools/stable/generated/mne.Evoked.html) object. This object defines many plotting functions, for example `plot_topomap` to look at the spatial distribution of the RSA values. By default, the signal is assumed to represent micro-Volts, so we need to explicitly inform the plotting function we are plotting RSA values and tweak the range of the colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_result.plot_topomap(rsa_result.times, units=dict(eeg='kendall-tau-a'), scalings=dict(eeg=1),\n",
    "                        cbar_fmt='%.4f', vmin=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2332cbc164264e6f8943b9b4aab1875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=319.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dsms = mne_rsa.dsm_epochs(epochs, dist_metric='sqeuclidean', spatial_radius=45, temporal_radius=0.05, tmin=0.15, tmax=0.25)\n",
    "rsa_result = mne_rsa.rsa(data_dsms, dsm_vis, metric='kendall-tau-a', n_jobs=6, n_data_dsms=319, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unsurprisingly, we get the highest correspondance between number of letters and EEG signal in areas in the visual cortex."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
